{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BERT Formality Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "16jOYzf22qt00go0AC6lUOGQpqR3SeXO-",
      "authorship_tag": "ABX9TyPh/mMcIiCl4dlcOhsd5+uh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lukehsu1999/Academic-and-Formality-Rewriter/blob/main/model/BERT_Formality_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr1SD_eE0E7Z"
      },
      "source": [
        "<h1>Installation</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGe62as4tqm5"
      },
      "source": [
        "!pip install -q transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0k48NBDKG9nV"
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "try:\n",
        "  import GPUtil as GPU\n",
        "  GPUs = GPU.getGPUs()\n",
        "  device='/gpu:0'\n",
        "except:\n",
        "  device='/cpu:0'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3qdN4QTHdb9"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNcLBg6W9bV9"
      },
      "source": [
        "from transformers import TFBertForSequenceClassification\n",
        "from transformers import BertTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZI2f1UGo0H_Z"
      },
      "source": [
        "<h1>Preparing Data</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "la3reo4Kdg1Q"
      },
      "source": [
        "put the path to the GYAFC below once you have gained access to the corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E8FdBMqdQdo"
      },
      "source": [
        "# these are academic-style\n",
        "\n",
        "path_to_formal_train_file=\"/content/drive/MyDrive/CityU/FYP/FormalSet/EMFR_formal_train\"\n",
        "path_to_informal_train_file=\"/content/drive/MyDrive/CityU/FYP/FormalSet/EMFR_informal_train\"\n",
        "\n",
        "path_to_formal_val_file = \"/content/drive/MyDrive/CityU/FYP/FormalSet/EMFR_formal_eval\"\n",
        "path_to_informal_val_file = \"/content/drive/MyDrive/CityU/FYP/FormalSet/EMFR_informal_eval\"\n",
        "\n",
        "# but these are\n",
        "path_to_formal_test_file=\"/content/drive/MyDrive/CityU/FYP/FormalSet/EMFR_formal_test\"\n",
        "path_to_informal_test_file=\"/content/drive/MyDrive/CityU/FYP/FormalSet/EMFR_informal_test\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSP7kT1hVUrl"
      },
      "source": [
        "Define how many lines from formal set you take (same num as from informal set).<br/>\n",
        "Total take=2*take_formal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txGYHbu8VJcA"
      },
      "source": [
        "#feel free to change\n",
        "#train_take_formal=1200\n",
        "#valid_take_formal=400 #validation set is useless if you don't run more than one epoch\n",
        "num_epochs= 1\n",
        "batch_size = 16\n",
        "period_less=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqkUyWzRUovP"
      },
      "source": [
        "Train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcwdlvWuqv0M",
        "outputId": "12d1c0ee-9e68-4df8-92e7-658cfd8086f3"
      },
      "source": [
        "trainformal=open(path_to_formal_train_file,\"r\")\n",
        "trainflines=trainformal.readlines()\n",
        "\n",
        "ds_train=[]\n",
        "\n",
        "#label: 1: formal; 0: informal\n",
        "\n",
        "for line in trainflines:\n",
        "\n",
        "  #only formal set have period concerns\n",
        "  if period_less:\n",
        "    line=line[:-2]\n",
        "\n",
        "  ds_train.append({'label':1,'text':line})\n",
        "\n",
        "traininformal=open(path_to_informal_train_file,\"r\")\n",
        "traininflines=traininformal.readlines()\n",
        "\n",
        "for line in traininflines:\n",
        "\n",
        "  ds_train.append({'label':0,'text':line})\n",
        "\n",
        "print(len(ds_train))\n",
        "if period_less:\n",
        "  print(\"period_less\")\n",
        "else:\n",
        "  print(\"include period\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "190112\n",
            "include period\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRjUGvpTU0MB"
      },
      "source": [
        "Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htPZ-ymQV-IO",
        "outputId": "134d6bb0-a15c-415b-b302-9bfcc4e6512d"
      },
      "source": [
        "valformal=open(path_to_formal_val_file,\"r\")\n",
        "valflines=valformal.readlines()\n",
        "\n",
        "ds_valid=[]\n",
        "\n",
        "#label: 1: formal; 0: informal\n",
        "\n",
        "for line in valflines:\n",
        "\n",
        "  #only formal set have period concerns\n",
        "  if period_less:\n",
        "    line=line[:-2]\n",
        "\n",
        "  ds_valid.append({'label':1,'text':line})\n",
        "\n",
        "valinformal=open(path_to_informal_val_file,\"r\")\n",
        "valinflines=valinformal.readlines()\n",
        "\n",
        "for line in valinflines:\n",
        "\n",
        "\n",
        "  ds_valid.append({'label':0,'text':line})\n",
        "\n",
        "print(len(ds_valid))\n",
        "\n",
        "if period_less:\n",
        "  print(\"period_less\")\n",
        "else:\n",
        "  print(\"include period\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19012\n",
            "include period\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgCyWuzYUv1a"
      },
      "source": [
        "GYAFC Given Test set (unchangeable, use as an performance comparison between different size of models)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C90Dzil_0_aC",
        "outputId": "8cd450bc-be24-4d2c-dcf1-a6ab8ce4b9d5"
      },
      "source": [
        "testformal=open(path_to_formal_test_file,\"r\")\n",
        "testflines=testformal.readlines()\n",
        "print(\"test formal lines cnt:\",len(testflines))\n",
        "ds_test=[]\n",
        "\n",
        "#label: 1: formal; 0: informal\n",
        "\n",
        "for line in testflines:\n",
        "  ds_test.append({'label':1,'text':line})\n",
        "\n",
        "testinformal=open(path_to_informal_test_file,\"r\")\n",
        "testinflines=testinformal.readlines()\n",
        "print(\"test informal lines cnt:\",len(testinflines))\n",
        "\n",
        "for line in testinflines:\n",
        "  ds_test.append({'label':0,'text':line})\n",
        "\n",
        "print(len(ds_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test formal lines cnt: 2101\n",
            "test informal lines cnt: 2748\n",
            "4849\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvYLZrhkXEjo"
      },
      "source": [
        "<h1>Data Preprocessing</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_Vm7uBJuOEL"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer=BertTokenizer.from_pretrained('bert-base-cased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p56FqMHvyqLI"
      },
      "source": [
        "# can be up to 512 for BERT\n",
        "max_length = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqlzDk2XysZP"
      },
      "source": [
        "def convert_example_to_feature(review):\n",
        "  \n",
        "  # combine step for tokenization, WordPiece vector mapping, adding special tokens as well as truncating reviews longer than the max length\n",
        "  \n",
        "  return tokenizer.encode_plus(review, \n",
        "                add_special_tokens = True, # add [CLS], [SEP]\n",
        "                max_length = max_length, # max length of the text that can go to BERT\n",
        "                pad_to_max_length = True, # add [PAD] tokens\n",
        "                return_attention_mask = True, # add attention mask to not focus on pad tokens\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWaQKR6AyzCX"
      },
      "source": [
        "def map_example_to_dict(input_ids, attention_masks, token_type_ids, label):\n",
        "  return {\n",
        "      \"input_ids\": input_ids,\n",
        "      \"token_type_ids\": token_type_ids,\n",
        "      \"attention_mask\": attention_masks,\n",
        "  }, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tihE_gYly6pX"
      },
      "source": [
        "def encode_examples(ds, limit=-1):\n",
        "\n",
        "  # prepare list, so that we can build up final TensorFlow dataset from slices.\n",
        "  input_ids_list = []\n",
        "  token_type_ids_list = []\n",
        "  attention_mask_list = []\n",
        "  label_list = []\n",
        "\n",
        "  if (limit > 0):\n",
        "      ds = ds.take(limit)\n",
        "    \n",
        "  for i in range(0,len(ds)): \n",
        "\n",
        "    bert_input = convert_example_to_feature(ds[i][\"text\"])\n",
        "  \n",
        "    input_ids_list.append(bert_input['input_ids'])\n",
        "    token_type_ids_list.append(bert_input['token_type_ids'])\n",
        "    attention_mask_list.append(bert_input['attention_mask'])\n",
        "    label_list.append(ds[i][\"label\"])\n",
        "\n",
        "  return tf.data.Dataset.from_tensor_slices((input_ids_list, attention_mask_list, token_type_ids_list, label_list)).map(map_example_to_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCE_k49Pi_kC"
      },
      "source": [
        "<h2>Encode the data<h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGJvy0qb9CPV"
      },
      "source": [
        "Train and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VddDYyK0ze_J"
      },
      "source": [
        "ds_train_encoded=encode_examples(ds_train).shuffle(len(ds_train)).batch(batch_size)\n",
        "ds_valid_encoded=encode_examples(ds_valid).shuffle(len(ds_train)).batch(batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpTpQdvq9Hhr"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCRk1-qi3FlD",
        "outputId": "e579a03a-01d1-4488-eb53-277975dc0a17"
      },
      "source": [
        "ds_test_encoded = encode_examples(ds_test).batch(batch_size)\n",
        "#ds_10Ktest_encoded=encode_examples(ds_10Ktest).batch(batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9J2UZMjXs85",
        "outputId": "3d73ccb3-adaa-4bf6-ca8d-c7eea7ea15f9"
      },
      "source": [
        "#length=lines/batch_size\n",
        "print(len(ds_train_encoded))\n",
        "print(len(ds_valid_encoded))\n",
        "print(len(ds_test_encoded))\n",
        "#print(len(ds_10Ktest_encoded))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11882\n",
            "1189\n",
            "304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UY9wugYyYgph"
      },
      "source": [
        "<h1>Model Compile & Train</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kI285OI3O9y",
        "outputId": "624c2a21-b6ac-4be4-cc5b-a6e00a9ba5f3"
      },
      "source": [
        "from transformers import TFBertForSequenceClassification\n",
        "import tensorflow as tf\n",
        "\n",
        "# recommended learning rate for Adam 5e-5, 3e-5, 2e-5\n",
        "learning_rate = 2e-5\n",
        "\n",
        "number_of_epochs = num_epochs #change 1 to 3\n",
        "\n",
        "\n",
        "\n",
        "# model initialization: building a model from scratch\n",
        "model = TFBertForSequenceClassification.from_pretrained('bert-base-cased')\n",
        "# if load weights from previous checkpoints\n",
        "path_to_model_weight = \"/content/drive/MyDrive/CityU/FYP/FormalSet/Epoch2Jun15\" \n",
        "model.load_weights(path_to_model_weight)\n",
        "\n",
        "# choosing Adam optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=1e-08)\n",
        "\n",
        "# we do not have one-hot vectors, we can use sparce categorical cross entropy and accuracy\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIxW3k3Y4BQN"
      },
      "source": [
        "\n",
        "bert_history = model.fit(ds_train_encoded, epochs=number_of_epochs, validation_data=ds_valid_encoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZDYGpRl7UCD"
      },
      "source": [
        "#need to have more than 1 epoch to show the curve\n",
        "print(bert_history.history.keys())\n",
        "print(bert_history)\n",
        "# summarize history for accuracy\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(bert_history.history['accuracy'])\n",
        "plt.plot(bert_history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(bert_history.history['loss'])\n",
        "plt.plot(bert_history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwK7OCmHbJFe"
      },
      "source": [
        "model.save_weights(\"/content/drive/MyDrive/CityU/FYP/FormalSet/Epoch3Jun15\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBo8u0z7aOjZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16a5d3e0-fc33-46b3-b771-378e5a569e3c"
      },
      "source": [
        "model.evaluate(ds_test_encoded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "304/304 [==============================] - 45s 147ms/step - loss: 0.1435 - accuracy: 0.9429\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1434587836265564, 0.9428748488426208]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnTMJWjk9Bqs"
      },
      "source": [
        "<h1>Evaluate with Test </h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ovx_iZiefMhU"
      },
      "source": [
        "put the path to your model below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQIP7SdMfIG1"
      },
      "source": [
        "path_to_model=\"/content/drive/MyDrive/CityU/FYP/Mar29Split/test/AcademicEpoch1June12\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WK5ktmvf9KZs",
        "outputId": "564e6279-3cb7-49f4-9ebc-a2cce185410a"
      },
      "source": [
        "#import model\n",
        "model=TFBertForSequenceClassification.from_pretrained('bert-base-cased')\n",
        "#paste the path to the saved weights\n",
        "model.load_weights(path_to_model)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fa018122950>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BysPi5Wy-r_b"
      },
      "source": [
        "learning_rate = 2e-5\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=1e-08)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsPQ-21W9cib"
      },
      "source": [
        "For Evaluating Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cA9jxJu1ZBKp",
        "outputId": "85dd2072-7324-4128-d421-e84125a127a5"
      },
      "source": [
        "model.evaluate(ds_test_encoded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "304/304 [==============================] - 47s 145ms/step - loss: 0.2853 - accuracy: 0.9091\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.28527092933654785, 0.909053385257721]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVi9NlUdjdL3"
      },
      "source": [
        "#model.evaluate(ds_10Ktest_encoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeNVjH3tB-Ox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feaec141-29e1-4d3c-b1af-b6e8872a69d1"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"tf_bert_for_sequence_classification_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bert (TFBertMainLayer)       multiple                  108310272 \n",
            "_________________________________________________________________\n",
            "dropout_75 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  1538      \n",
            "=================================================================\n",
            "Total params: 108,311,810\n",
            "Trainable params: 108,311,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a00ciUYD9gIM"
      },
      "source": [
        "<h1>Tryouts</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qICkL_FdKwhl"
      },
      "source": [
        "!pip install -q transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiKnji9gK1JR"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from transformers import TFBertForSequenceClassification\n",
        "from transformers import BertTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogJjoskgMcO4"
      },
      "source": [
        "tokenizer=BertTokenizer.from_pretrained('bert-base-cased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JRUGy9oUffl"
      },
      "source": [
        "def getPrediction(sentence,thismodel):\n",
        "  inputs=tokenizer(sentence,return_tensors=\"tf\")\n",
        "  outputs=thismodel(inputs,return_dict=True)\n",
        "  #print(outputs)\n",
        "  #print(outputs.loss)\n",
        "  #print(outputs.logits)\n",
        "  logits=outputs.logits\n",
        "  probs = tf.nn.softmax(logits)\n",
        "  prediction = tf.math.argmax(probs, axis=1)\n",
        "  print(f\"probs {probs}\")\n",
        "  if prediction[0]==1:\n",
        "    print(\"Formal\")\n",
        "    return 1\n",
        "  else:\n",
        "    print(\"Informal\")\n",
        "    return 0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KBnaLg3PLmB"
      },
      "source": [
        "Please go to https://drive.google.com/drive/folders/1mDlYfLHuIiNA8kHZooXAqpk5eZBOj39o?usp=sharing to download the model weights\n",
        "and paste the path in the path_to_model_weight below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWB0DbM2LTwR"
      },
      "source": [
        "path_to_model_weight=\"/content/drive/MyDrive/CityU/FYP/Bert_Formality_Classifier/Feb21test\"\n",
        "demo_model=TFBertForSequenceClassification.from_pretrained('bert-base-cased')\n",
        "demo_model.load_weights(path_to_model_weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74sL2SxvKiHS"
      },
      "source": [
        "#put your sentence in the input_sentence\n",
        "input_sentence=\"I dunno wat happening here.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWFO3vG-LN5R"
      },
      "source": [
        "getPrediction(input_sentence,demo_model) #demo_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqYw3jmt9tIk"
      },
      "source": [
        "<h1> Saving model weights <h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bon39kUU1SqA"
      },
      "source": [
        "model.save_weights(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m-n5XLnLiio"
      },
      "source": [
        "Insight: adding \".\" at the end of the sentence makes it too much more formal. Need to rethink about it"
      ]
    }
  ]
}
