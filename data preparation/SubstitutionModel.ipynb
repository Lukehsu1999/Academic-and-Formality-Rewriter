{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SubstitutionModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1LykAzkGDK-tpPoTnPnOufaC9gL3-B5PN",
      "authorship_tag": "ABX9TyMNfkXuR4Tlz3pGezTebIMD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lukehsu1999/Academic-and-Formality-Rewriter/blob/main/SubstitutionModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G93dE_8jbLDH"
      },
      "source": [
        "Libraries needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3QOpzirbOZ_"
      },
      "source": [
        "import string\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gi-Imwp1acQn"
      },
      "source": [
        "<h2>Replacement Dictionaries</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QE4Qka6Z8Px"
      },
      "source": [
        "#Basic Taboo Dicts\n",
        "sentence_start_dict={\"DictName\":\"sentence_start\", 'Also':\"Moreover,\", 'So':\"Therefore\", 'And':\"#AND#\", 'Besides':\"Additionally,\"} #And: should be removed\n",
        "vague_word_dict={\"DictName\":\"vague_word\", \n",
        "      'stuff':\"#sTUFF\", 'Stuff':\"#STUFF\", 'thing':\"#tHING\", 'Thing':\"#THING\"}\n",
        "      #'anything':\"#ANYTHING#\", 'Anything':\"#ANYTHING#\", 'nothing':\"#NOTHING#\",'Nothing':\"#NOTHING#\", \n",
        "      #'something':\"#SOMETHING#\", 'Something':\"#Something\", 'everything':\"#everything\", 'Everything':\"#Everything\"}\n",
        "\n",
        "#she's: she is OR she has\n",
        "#he'd: he had OR he would\n",
        "#we'd: we had OR we would OR we should\n",
        "#we're: we are OR we were\n",
        "#it's: it is OR it has\n",
        "#who's: who is OR who has\n",
        "informal_contraction_dict={\"DictName\":\"contraction\", \n",
        "              \"I'd\":\"#I'D\", \n",
        "              \"I'll\":\"I will\",\"i'll\":\"I will\", \"I've\":\"I have\",\"i've\":\"I have\",\"I'm\":\"I am\",\"i'm\":\"I am\", \n",
        "              \"you're\":\"you are\", \"You're\":\"You are\", \"you'll\":\"you will\", \"You'll\":\"You will\",\n",
        "              \"you've\":\"you have\", \"You've\":\"You have\",\n",
        "              \"you'd\":\"#yOU'D\",\"You'd\":\"#YOU'D\",\n",
        "              \"she's\":\"#sHE'S\", \"She's\":\"#SHE'S\", \"he's\":\"#hE'S\", \"He's\":\"#HE'S\",\n",
        "              \"she'd\":\"#sHE'D\", \"he'd\":\"#hE'D\",\n",
        "              \"She'd\":\"#SHE'D\", \"He'd\":\"#HE'D\",  \n",
        "              \"she'll\":\"she will\", \"he'll\":\"he will\",\n",
        "              \"She'll\":\"She will\", \"He'll\":\"He will\", \n",
        "              \"they'll\":\"they will\", \"they're\":\"they are\", \"they've\":\"they have\", \n",
        "              \"They'll\":\"They will\", \"They're\":\"They are\", \"They've\":\"They have\",\n",
        "              \"they'd\":\"#tHEY'D\", \"They'd\":\"#THEY'D\", \n",
        "              \"we'd\":\"#wE'D\",\"We'd\":\"#WE'D\",\n",
        "              \"we're\":\"we are\",\n",
        "              \"We're\":\"We are\",\n",
        "              \"we'll\":\"we will\", \"we've\":\"we have\",\n",
        "              \"We'll\":\"We will\", \"We've\":\"We have\",\n",
        "              \"it's\":\"#iT'S\", \"It's\":\"#IT'S\",\n",
        "              \"it'd\":\"#iT'D\",\"It'd\":\"#IT'D\",\n",
        "              \"it'll\":\"it will\", \"that's\":\"that is\", \"there's\":\"there is\", \"where's\":\"where is\", \"let's\":\"let us\",\n",
        "              \"It'll\":\"It will\", \"That's\":\"That is\", \"There's\":\"There is\", \"Where's\":\"Where is\", \"Let's\":\"Let us\",\n",
        "              \"that'll\":\"that will\", \"That'll\":\"That will\",\n",
        "              \"that'd\":\"that would\", \"That'd\":\"That would\",\n",
        "              \"can't\":\"can not\", \"couldn't\":\"could not\", \"didn't\":\"did not\", \"doesn't\":\"does not\", \"don't\":\"do not\",\n",
        "              \"Can't\":\"Can not\", \"Couldn't\":\"Could not\", \"Didn't\":\"Did not\", \"Doesn't\":\"Does not\", \"Don't\":\"Do not\",\n",
        "              \"hadn't\":\"had not\", \"hasn't\":\"has not\", \"isn't\":\"is not\", \"shouldn't\":\"should not\", \"wasn't\":\"was not\",\n",
        "              \"Hadn't\":\"Had not\", \"Hasn't\":\"Has not\", \"Isn't\":\"Is not\", \"Shouldn't\":\"Should not\", \"Wasn't\":\"Was not\", \n",
        "              \"haven't\":\"have not\", \"Haven't\":\"Have not\",\n",
        "              \"aren't\":\"are not\", \"Aren't\":\"Are not\",\n",
        "              \"weren't\":\"were not\", \"Weren't\":\"Were not\",\n",
        "              \"wouldn't\":\"would not\", \"Wouldn't\":\"Would not\",\n",
        "              \"won't\":\"will not\", \"wouldn't\":\"would not\", \"could've\":\"could have\", \"might've\":\"might have\", \"must've\":\"must have\",\n",
        "              \"Won't\":\"Will not\", \"Wouldn't\":\"Would not\", \"Could've\":\"Could have\", \"Might've\":\"Might have\", \"Must've\":\"Must have\",\n",
        "              \"should've\":\"should have\", \"would've\":\"would have\",\n",
        "              \"Should've\":\"Should have\", \"Would've\":\"Would have\",\n",
        "              \"who's\":\"#wHO'S\", \"Who's\":\"#WHO'S\",\n",
        "              \"who'll\":\"who will\", \"Who'll\":\"Who will\",\n",
        "              \"who'd\":\"#wHO'D\", \"Who'd\":\"#WHO'D\",\n",
        "              \"why'd\":\"why would\", \"Why'd\":\"Why would\",\n",
        "              \"how's\":\"how is\", \"How's\":\"How is\",\n",
        "              \"how'd\":\"how would\",\"How'd\":\"How would\",\n",
        "              \"what's\":\"what is\", \"What's\":\"What is\",\n",
        "              \"here's\":\"here is\", \"Here's\":\"Here is\"}\n",
        "\n",
        "informal_others_dict={\"DictName\":\"others\", \"till\":\"untill\", \"Till\":\"Untill\"}\n",
        "informal_frequency_dict={\"DictName\":\"frequency\", \n",
        "              \"always\":\"#aLWAYS\", \"Always\":\"#ALWAYS\", \"never\":\"#nEVER\", \"Never\":\"#NEVER\"}\n",
        "#too: I am a student, too. vs. he is too awesome\n",
        "informal_intensifier_dict={\"DictName\":\"intensifier\", \"very\":\"\", \"Very\":\"\", \"extremely\":\"\", \"Extremely\":\"\", \"really\":\"#rEALLY\", \"Really\":\"#REALLY\", \n",
        "              \"too\":\"#tOO\", \"Too\":\"#TOO\", \"so\":\"#sO\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNkGFBJo4oEc"
      },
      "source": [
        "#incomplete taboo dicts: will not substitute them for now (Feb 23)\n",
        "informal_subjective_dict={\"DictName\":\"subjective\", \"naturally\":\"\", \"Naturally\":\"#NATURALLY\", \"obviously\":\"clearly\", \"Obviously\":\"Clearly\"}\n",
        "good_bad_dict={\"DictName\":\"good_bad\", \"good\":\"good\", \"Good\":\"#GOOD\", \"bad\":\"#bAD\", \"Bad\":\"#BAD\"}\n",
        "superlatives_dict={\"DictName\":\"superlatives\", \"best\":\"#bEST\", \"Best\":\"#BEST\", \"worst\":\"#wORST\", \"Worst\":\"#WORST\"}\n",
        "personal_preference_dict={\"DictName\":\"personal_preference\", \"like\":\"#lIKE\", \"likes\":\"#lIKES\", \"liked\":\"#lIKED\", \"love\":\"#lOVE\", \"loves\":\"#lOVES\", \"loved\":\"#lOVED\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCmq5WC1grR5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj3QIQRo7UtP"
      },
      "source": [
        "#extended taboo dicts: will not substitute them for now (Feb 23)\n",
        "informal_second_person_dict={\"DictName\":\"second_person\", \"you\":\"you\", \"You\":\"You\", \"your\":\"your\", \"Your\":\"Your\"}\n",
        "first_person_dict={\"DictName\":\"first_person\", \"I\":\"I\", \"We\":\"We\", \"we\":\"we\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQGXt1SL4vbP"
      },
      "source": [
        "For informal phrases dict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4O0RZimI4x5L"
      },
      "source": [
        "def match_with_phrase_dict(words, i, word):\n",
        "  if i+1<len(words) and (word=='a' or word=='A') and words[i+1]=='bit': \n",
        "    return \"a bit\"\n",
        "  elif i+2<len(words) and (word==\"a\" or word=='A') and words[i+1]==\"lot\" and words[i+2]==\"of\":\n",
        "    return 'a lot of'\n",
        "  elif i+2<len(words) and (word==\"a\" or word=='A') and words[i+1]==\"couple\" and words[i+2]==\"of\":\n",
        "    return 'a couple of'\n",
        "  elif i+1<len(words) and (word==\"kind\" or word==\"Kind\") and words[i+1]==\"of\":\n",
        "    return 'kind of'\n",
        "  elif i+1<len(words) and word==\"sort\" and words[i+1]==\"of\":\n",
        "    return 'sort of'\n",
        "  elif i+1<len(words) and (word==\"of\" or word==\"Of\") and words[i+1]==\"course\":\n",
        "    return 'of course'\n",
        "  elif i+2<len(words) and (word==\"a\" or word==\"A\") and words[i+1]==\"long\" and words[i+1]==\"time\":\n",
        "    return 'a long time'\n",
        "  elif i+1<len(words) and (word==\"a\" or word==\"A\") and words[i+1]==\"while\":\n",
        "    return 'a while'\n",
        "  else:\n",
        "    return -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWAti026oTav"
      },
      "source": [
        "Things to think about substituing sentences: </br>\n",
        "word sequence need to be the same <br>\n",
        "puctuation need to be preserved <br>\n",
        "there might be multiple words to substitute in the sentence -> index will change <br>\n",
        "There might be duplicate target words in the sentence: you should've won, you really should've become the winner <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDchuaji3D3E"
      },
      "source": [
        "<h2>Substitution Function </h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ob3209vb7vB"
      },
      "source": [
        "def get_substituted_sentence(sentence_set, replace_dict_set):\n",
        "  new_line_set=[]\n",
        "  for line in sentence_set:\n",
        "    #preprocessing\n",
        "    mypunct=string.punctuation[0:6]+string.punctuation[7:len(string.punctuation)] #except '\n",
        "    punctless_sentence=line.translate(str.maketrans('','',mypunct))\n",
        "    words=punctless_sentence.split()\n",
        "    new_line=line\n",
        "    for i,word in enumerate(words):\n",
        "      for replace_dict in replace_dict_set:\n",
        "        if word in replace_dict.keys():\n",
        "          #print(word)\n",
        "          #print(replace_dict[word])\n",
        "          new_line=new_line.replace(word,replace_dict[word])\n",
        "    new_line_set.append(new_line)\n",
        "\n",
        "  return new_line_set\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRL9ppAP2r3d"
      },
      "source": [
        "<h2>Execution</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUPPXYh53NZi"
      },
      "source": [
        "Replacement Dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDOXWj9b2t4x"
      },
      "source": [
        "basic_replace_dict_set=[sentence_start_dict,\n",
        "        informal_contraction_dict, informal_frequency_dict, \n",
        "        informal_intensifier_dict, informal_others_dict]\n",
        "#remove vague_word_dict temporarily\n",
        "incomplete_taboo_dict_set=[informal_subjective_dict, good_bad_dict,\n",
        "        superlatives_dict, personal_preference_dict]\n",
        "extended_taboo_dict_set=[informal_second_person_dict, first_person_dict]\n",
        "\n",
        "replace_dict_set=[]\n",
        "replace_dict_set+=basic_replace_dict_set\n",
        "#replace_dict_set+=incomplete_taboo_dict_set\n",
        "#replace_dict_set+=extended_taboo_dict_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Issh8XIm6lvl"
      },
      "source": [
        "Get corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d86e8qEX6urI",
        "outputId": "03f78347-7ad5-4e0b-bd12-3f2852ca84b0"
      },
      "source": [
        "#path to the dataset\n",
        "path_to_dataset=\"/content/drive/MyDrive/CityU/FYP/Mar29Split/test/FR/formal\"\n",
        "\n",
        "#open file\n",
        "f=open(path_to_dataset,\"r\")\n",
        "lines=f.readlines()\n",
        "partial_lines=lines[0:10]\n",
        "print(partial_lines)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I mean that you have to really be her friend.\\n', 'Are you posing a rhetorical question?\\n', 'Men pretend to love in order to have intercourse; women pretend to enjoy intercourse in order to get love.\\n', 'I do not intend to be mean.\\n', 'I would estimate an average of 45% initially but then, once you become acquainted with the person, perhaps 15%.\\n', 'Because some women send subtle messages to men rather than being clear.\\n', 'Let us purchase coffee and converse and proceed from that point!\\n', 'Also, i dislike it when my father is unhappy.\\n', 'Ask him if you should go see a doctor.\\n', 'You can post more questioins on Yahoo! answers.\\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2ztni4eYqQ2"
      },
      "source": [
        "Get replace sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wMuzcFQap0M"
      },
      "source": [
        "result=get_substituted_sentence(lines,replace_dict_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixQK5RB2YyRy"
      },
      "source": [
        "Save to file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvXA_eKKZTDi",
        "outputId": "35d03f27-91e1-402a-ca7f-52725850b512"
      },
      "source": [
        "path_to_write_file=\"/content/drive/MyDrive/CityU/FYP/Mar29Split/test/FR/formal_auto_substituted\"\n",
        "f=open(path_to_write_file,\"w\") #w: overwrite; a: append\n",
        "for lines in result:\n",
        "  f.write(lines)\n",
        "f=open(path_to_write_file,\"r\")\n",
        "lines=f.readlines()\n",
        "print(lines[0:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I mean that you have to #rEALLY be her friend.\\n', 'Are you posing a rhetorical question?\\n', 'Men pretend to love in order to have intercourse; women pretend to enjoy intercourse in order to get love.\\n', 'I do not intend to be mean.\\n', 'I would estimate an average of 45% initially but then, once you become acquainted with the person, perhaps 15%.\\n', 'Because some women send subtle messages to men rather than being clear.\\n', 'Let us purchase coffee and converse and proceed from that point!\\n', 'Moreover,, i dislike it when my father is unhappy.\\n', 'Ask him if you should go see a doctor.\\n', 'You can post more questioins on Yahoo! answers.\\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibSA2cm656sp"
      },
      "source": [
        "<h2> Exception: Phrase Dict </h2>\n",
        "<p> will manually update it </p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yM3pxC0C6Dm2"
      },
      "source": [
        "phrase_dict={\"DictName\":\"phrases\", 'a bit':'somewhat', 'a lot of':'a great number of', \n",
        "      'a couple of':'several', 'kind of':'somewhat', 'sort of':'somewhat', \"of course\":\"clearly\", \n",
        "      'a long time':\"#a LONG TIME#\", 'a while':\"#a WHILE#\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "o1gojlArpVLn",
        "outputId": "1d454090-8675-4070-e0d0-041ddbacde28"
      },
      "source": [
        "path_to_write_file=\"/content/drive/MyDrive/CityU/FYP/Datasets/GYAFC/GYAFC_Corpus/Entertainment_Music/train/grammarlylized\"\n",
        "f=open(path_to_write_file,\"r\")\n",
        "lines=f.readlines()\n",
        "print(lines[-10:-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnicodeDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-4d139441a569>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath_to_write_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/CityU/FYP/Datasets/GYAFC/GYAFC_Corpus/Entertainment_Music/train/grammarlylized\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_write_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x93 in position 2515: invalid start byte"
          ]
        }
      ]
    }
  ]
}
